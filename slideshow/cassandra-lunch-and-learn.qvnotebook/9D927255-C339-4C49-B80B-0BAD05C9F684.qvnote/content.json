{
  "title": "cassandra-lunch-and-learn",
  "cells": [
    {
      "type": "markdown",
      "data": "# Cassandra Lunch and Learn\n## September 22, 2017\n\n---\n\n# History\n- Developed at Facebook to power Inbox Search\n- One of the authors of Amazon's DynamoDB\n\n---\n\n# History - Releases\n- 2008 - Released as Open Source\n- 2009 - Apache Incubator\n- 2010 - Graduated to top-tier Apache project\n- 2010 - Cassandra 0.6 (Probably the first version used at Socrata for first version of Balboa)\n- 2015 - Cassandra 2.2 (2.2.10, released 6/2017, is the version we are currently running)\n- 2015 - Cassandra 3.0 (3.11, released 6/2017, is the latest stable version)\n- ???? - Cassandra 4.0 (Will put 2.2.x out of support, and 3.x into 6 months of support)\n  - 92% of the project's JIRA tickets tagged for v4.0 are complete\n\n---\n\n# Why Cassandra?\n## CAP Theorem\n\n---\n\n# CAP Theorem\n\n> Parenting CAP Theorem:  \n>   \n> Consistent sleep  \n> Available time  \n> Peace and quiet  \n>   \n> Choose none.\n> \n> — Dan Woods (@danveloper) [February 21, 2017](https://twitter.com/danveloper/status/833861643536834560)\n\n---\n\n# CAP Theorem\n\n> The CAP theorem says that a paper on distributed systems cannot be simultaneously Applicable, Comprehensible and free from Paywall.\n> \n> — Chris Ford (@ctford) [July 3, 2017](https://twitter.com/ctford/status/881990271881314304)\n\n---\n\n# CAP Theorem\n\nIt is impossible for a distributed computer system to simultaneously provide more than two of the following three guarantees:\n- Consistency - Every read receives the most recent write or an error\n- Availability - Every request receives a (non-error) response – without guarantee that it contains the most recent write\n- Partition-tolerant - The system continues to operate despite an arbitrary number of messages being dropped (or delayed) by the network between nodes\n\n---\n\n# Cassandra and CAP\n\nConsidered an AP system, where it prioritizes Availability and Partition-tolerance.  However, it is tunable via replication factor and consistency level to provide high consistency\n\n---\n\n# Biggest Selling Point\n\nHigh performance for writes, scalable horizontally due to its peer-based clustering, with a number of fault tolerance mechanisms\n\n---\n\n# How Cassandra Works\n\n---\n\n# Clustering\n\n- No \"master\" node, all nodes are peers\n- Performance generally scales linearly with number of nodes (e.g. 2 nodes serving 100,000 transactions per second should scale to 4 nodes service 200,000 tx/s)\n\n---\n\n# Replication\n\n- The number of replicas in the cluster, i.e. copies of a particular piece of data across all nodes, is configurable on a per-keyspace (table) basis\n- If any node in a cluster goes down, one or more copies of that node’s data is available on other machines in the cluster\n- Can be configured to work across one datacenter, many datacenters, and multiple cloud availability zones\n\n---\n\n# Consistency\n\n- Consistency refers to how up-to-date and synchronized a row of data is on all of its replicas\n- Extends the concept of eventual consistency by offering tunable consistency for any given read or write operation, the client application decides how consistent the requested data should be\n\n---\n\n# Read Consistency Options\n\n| Level | Description |\n| --- | --- |\n| ALL | Returns the record with the most recent timestamp after all replicas have responded. The read operation will fail if a replica does not respond. |\n| EACH_QUORUM | Returns the record with the most recent timestamp once a quorum of replicas in each data center of the cluster has responded. |\n| LOCAL_QUORUM | Returns the record with the most recent timestamp once a quorum of replicas in the current data center as the coordinator node has reported. |\n\n---\n\n# Read Consistency Options (cont.)\n\n| Level | Description |\n| --- | --- |\n| LOCAL_ONE | Returns a response from the closest replica, as determined by the snitch, but only if the replica is in the local data center. |\n| ONE | Returns a response from the closest replica, as determined by the snitch. By default, a read repair runs in the background to make the other replicas consistent. |\n| QUORUM | Returns the record with the most recent timestamp after a quorum of replicas has responded regardless of data center. |\n\n---\n\n# Write Consistency Options (a subset)\n\n| Level | Description |\n| --- | --- |\n| ANY | A write must be written to at least one node. If all replica nodes for the given row key are down, the write can still succeed after a _hinted handoff_ has been written. If all replica nodes are down at write time, an ANY write is not readable until the replica nodes for that row have recovered. |\n| ALL | A write must be written to the commit log and memory table on all replica nodes in the cluster for that row. |\n\n---\n# Write Consistency Options (cont.)\n\n| Level | Description |\n| --- | --- |\n| LOCAL_QUORUM | A write must be written to the commit log and memory table on a quorum of replica nodes in the same data center as the coordinator node. Avoids latency of inter-data center communication. |\n| ONE | A write must be written to the commit log and memory table of at least one replica node. |\n\n---\n\n# How is Data Stored?\n\n---\n\n## The Write Path\n\n![IMAGE](http://docs.datastax.com/en/archived/cassandra/2.0/cassandra/images/dml_write-process_12.png)\n\n---\n\n# The Write Path\n\n- Mem table - Fast immediate access\n- Commit Log - Immediate durability\n- SSTable - Long-term durability and consistency\n\n---\n\n# The Read Path\n\n![IMAGE](http://docs.datastax.com/en/archived/cassandra/2.0/cassandra/images/dml_caching-reads_12.png)\n\n---\n\n# The Read Path\n\nCassandra must combine results from the active memtable and potentially multiple SSTables to satisfy a read.\n\n- Bloom filter - probability that a particular sstable has data before actually going to disk\n- Partition key cache - What sstable has the data?\n  - Partition Summary - Where on disk could the data be?\n  - Partition Index - Where exactly on disk is the data?\n- Compression Offsets - Where in the sstable is the data?\n- Data - There it is!\n\n---\n\n# Repairs\n\n---\n\n# Repairs\n## Getting consistent\n\nRepairs (or anti-entropy operations) are Cassandra's mechanism for maintaining consistency across the cluster in the event of network issues\nand node outages.\n\n---\n\n# Repairs\n## Getting consistent\n\nRepairs are performed on read of data when it is determined that a node that should have the data does not have it.  Additionally,\nwe have repairs scheduled to run across our cluster every few days.  This is done by calculate the hash of parts of the data and comparing that hash\nwith where it should exists.  In the event that data is missing, the data is streamed from a node that has it to the node that does not.\n\n---\n\n# API\n\n---\n\n# API\n\nCassandra historically has provided two APIs/network transports for working with it.  \"Thrift\" was the initial transport supported, but was\nsuperseded by the native \"CQL\" transport in later versions of Cassandra.  In version 3.0 of Cassandra, thrift is no longer active by default\nand is basically deprecated.\n\nThe argument for using CQL over thrift primarily comes down to if you want to use more modern capabilities of Cassandra, but CQL is the preferred\nmechanism for working with Cassandra now and going forward.\n\n---\n\n# Datastax\n\n---\n\n# Datastax\n\nCommercial entity that provides their own flavor of Cassandra in the form of Datastax Enterprise.  Also fosters the development of libraries\nto use with Cassandra, and provides some online training courses that are helpful for getting a deeper understanding of Cassandra\noperations and development.\n\n---\n\n# Datastax Driver\n\nDatastax Driver is the library that we would ideally be using everywhere for interacting with Cassandra.  This provides support for the native\ntransport when communicating with Cassandra, connection pooling, and resiliency.\n\nDelta Importer 2 seems to be the only Socrata project that still uses the\nnow-deprecated and no longer supported Astyanax driver.\n\n---\n\n# Tools\n\n---\n\n# Tools\n## nodetool\n\n`nodetool` - The most important tool for working with Cassandra nodes.\n\nProvides the ability to check the state of the cluster and individual nodes, manipulate\nthe cluster, snapshot nodes, run consistency repairs, and shutdown nodes cleanly.\n\n---\n\n# Tools\n## `nodetool status`\n## See the status of the cluster, what nodes are part of it, their load of the data, and their status\n\n```\nDatacenter: us-west-2\n=====================\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address        Load       Tokens       Owns    Host ID                               Rack\nUN  10.110.33.188  5.18 GB    256          ?       c196cd0d-812a-4795-a423-a7d8799eee00  2a\nUN  10.110.42.252  5.33 GB    256          ?       bd9918c2-635f-455d-90d5-3c59daa365f4  2c\nUN  10.110.37.55   4.9 GB     256          ?       885593d3-8fde-4962-a902-41beec305ba7  2b\n```\n\n---\n\n# Tools\n## `nodetool describecluster`\n## More detail about the cluster\n\n```\nCluster Information:\n\tName: Socrata Metrics Cluster\n\tSnitch: org.apache.cassandra.locator.DynamicEndpointSnitch\n\tPartitioner: org.apache.cassandra.dht.RandomPartitioner\n\tSchema versions:\n\t\t0c0e24fd-ac04-3887-8cc0-eb53235fd4eb: [10.110.42.252, 10.110.33.188, 10.110.37.55]\n```\n\n---\n\n# Tools\n## `nodetool info`\n## Information about the node it is run on, e.g. heap usage, uptime, cache stats\n\n```\nID                     : c196cd0d-812a-4795-a423-a7d8799eee00\nGossip active          : true\nThrift active          : true\nNative Transport active: true\nLoad                   : 5.18 GB\nGeneration No          : 1505150833\nUptime (seconds)       : 883752\nHeap Memory (MB)       : 574.09 / 1976.00\nOff Heap Memory (MB)   : 143.16\nData Center            : us-west-2\nRack                   : 2a\nExceptions             : 0\nKey Cache              : entries 1038840, size 87.55 MB, capacity 98 MB, 6292004 hits, 9409776 requests, 0.669 recent hit rate, 14400 save period in seconds\nRow Cache              : entries 0, size 0 bytes, capacity 0 bytes, 0 hits, 0 requests, NaN recent hit rate, 0 save period in seconds\nCounter Cache          : entries 207445, size 26.63 MB, capacity 49 MB, 948966 hits, 1331745 requests, 0.713 recent hit rate, 7200 save period in seconds\n```\n\n---\n\n# Tools\n## `nodetool tpstats`\n## Thread pool stats - what threads are active on this node, e.g. compaction, anti-entropy (repair), blocked threads\n\n```\nPool Name                    Active   Pending      Completed   Blocked  All time blocked\nMutationStage                     0         0        2086964         0                 0\nReadStage                         0         0       64182133         0                 0\nRequestResponseStage              0         0       26635830         0                 0\nReadRepairStage                   0         0        6029181         0                 0\nCounterMutationStage              0         0         587910         0                 0\nHintedHandoff                     0         0             20         0                 0\nMiscStage                         0         0              0         0                 0\nCompactionExecutor                0         0         887421         0                 0\nMemtableReclaimMemory             0         0           4231         0                 0\nPendingRangeCalculator            0         0              8         0                 0\nGossipStage                       0         0        2651509         0                 0\nMigrationStage                    0         0              5         0                 0\nMemtablePostFlush                 0         0         125356         0                 0\nValidationExecutor                0         0          90872         0                 0\nSampler                           0         0              0         0                 0\nMemtableFlushWriter               0         0           3859         0                 0\nInternalResponseStage             0         0            137         0                 0\nAntiEntropyStage                  0         0         346369         0                 0\nCacheCleanupExecutor              0         0              0         0                 0\nNative-Transport-Requests         0         0      102993281         0                 0\n\nMessage type           Dropped\nREAD                         0\nRANGE_SLICE                  0\n_TRACE                       0\nMUTATION                     0\nCOUNTER_MUTATION             0\nREQUEST_RESPONSE             0\nPAGED_RANGE                  0\nREAD_REPAIR                  0\n```\n\n---\n\n# Tools\n## `nodetool netstats`\n## Network stats - mostly if data is streaming between nodes\n\n```\nMode: NORMAL\nNot sending any streams.\nRead Repair Statistics:\nAttempted: 5517249\nMismatch (Blocking): 0\nMismatch (Background): 17\nPool Name                    Active   Pending      Completed   Dropped\nLarge messages                  n/a         0           1731         0\nSmall messages                  n/a         0       50627207         0\nGossip messages                 n/a         0        2651909         0\n```\n\n---\n\n# Tools\n## cqlsh\n\n`cqlsh` - CQL shell\n\nIs the equivalent of `psql` for Cassandra.  Allows executing queries against a Cassandra node/cluster. \n\n```\nConnected to Socrata Metrics Cluster at 10.110.33.188:9042.\n[cqlsh 5.0.1 | Cassandra 2.2.10 | CQL spec 3.3.1 | Native protocol v4]\nUse HELP for help.\ncqlsh> describe keyspaces;\n\ngovstat        system_auth  \"OpsCenter\"    books               \"GovStat\"\nsystem_traces  system       \"Metrics2012\"  system_distributed  delta_importer_2\n\ncqlsh>\n```\n\n---\n\n# Tools\n## jmxterm\n\n`jmxterm` - Command-line interface for working with JMX\n\nThis has been useful for pulling data out of Cassandra and, specifically, stopping consistency repairs that are in progress.\nSee the Cassandra Playbook for how to stop a repair.\n\n---\n\n# Cassandra at Socrata\n## Clusters\n\n- Apps Cluster\n  - Delta Importer 2\n  - Phiddipides (metadata)\n- Metrics Cluster\n  - Balboa (tenant metrics)\n  - Procrustes\n- Apps-Metrics Cluster (RC and EU)\n  - Everything on one cluster\n  - Why aren't all the clusters like this?\n    - Differing partitioners between clusters\n\n---\n\n# Cassandra at Socrata\n## Services\n\n- Delta Importer 2\n  - \"Partition table\" for a filesystem distributed over S3\n  - \"Greyboard\" logs\n- Phidippides\n  - Key/Value metadata for datasets\n- Balboa\n  - Time-series data of collected metrics\n  - Aggregating counters and absolute count values\n- Procrustes\n  - Goal data and ???\n\n---\n\n# Cassandra and On-Call\n\nThe OpsDocs for Cassandra have been updated to reflect the current state of Cassandra operations\nat Socrata.  Additionally, the Cassandra playbook has been updated with ways to attack some\nscenarios that we have encountered recently with Cassandra.\n\nWhen on-call, and something looks like a Cassandra issue:\n\n**Refer to the OpsDoc, then the Playbook. Otherwise, flag down someone who knows Cassandra (presently Ragan, someday more 🤞)**\n\n---\n\n# Hands-on Time\n\n**Slack Channel: #cassandra-cluster-fun**\n\nLet's break into groups of three people or so, clone the repository https://github.com/raganw/cassandra-lunch-and-learn,\nand take a look at the `cluster-exercise` directory.\n\n---"
    }
  ]
}