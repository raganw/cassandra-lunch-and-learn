{
  "title": "cassandra-lunch-and-learn",
  "cells": [
    {
      "type": "markdown",
      "data": "# Cassandra Lunch and Learn\n## September 22, 2017\n\n---\n\n# History\n- Developed at Facebook to power Inbox Search\n- One of the authors of Amazon's DynanamoDB\n\n---\n\n# History - Releases\n- 2008 - Released as Open Source\n- 2009 - Apache Incubator\n- 2010 - Graduated to top-tier Apache project\n- 2010 - Cassandra 0.6 (Probably the first version used at Socrata for first version of Balboa)\n- 2015 - Cassandra 2.2 (2.2.10, released 6/2017, is the version we are currently running)\n- 2015 - Cassandra 3.0 (3.11, released 6/2017, is the latest stable version)\n- ???? - Cassandra 4.0 (Will put 2.2.x out of support, and 3.x into 6 months of support)\n  - 92% of the project's JIRA tickets tagged for v4.0 are complete\n\n---\n\n# Why Cassandra?\n## CAP Theorem\n\n---\n\n# CAP Theorem\n\n> Parenting CAP Theorem:  \n>   \n> Consistent sleep  \n> Available time  \n> Peace and quiet  \n>   \n> Choose none.\n> \n> — Dan Woods (@danveloper) [February 21, 2017](https://twitter.com/danveloper/status/833861643536834560)\n\n---\n\n# CAP Theorem\n\n> The CAP theorem says that a paper on distributed systems cannot be simultaneously Applicable, Comprehensible and free from Paywall.\n> \n> — Chris Ford (@ctford) [July 3, 2017](https://twitter.com/ctford/status/881990271881314304)\n\n---\n\n# CAP Theorem\n\nIt is impossible for a distributed computer system to simultaneously provide more than two of three of the following guarantees:\n- Consistency - Every read receives the most recent write or an error\n- Availability - Every request receives a (non-error) response – without guarantee that it contains the most recent write\n- Partition-tolerant - The system continues to operate despite an arbitrary number of messages being dropped (or delayed) by the network between nodes\n\n---\n\n# Cassandra and CAP\n\nConsidered an AP system, where it prioritizes Availability and Partition-tolerance.  However, as we will see, it is tunable via replication factor and consistency level to provide high consistency\n\n---\n\n# Biggest Selling Point\n\nHigh performance for writes, scalable horizontally due to its peer-based clustering, with a number of fault tolerance mechanisms\n\n---\n\n# How Cassandra Works\n\n---\n\n# Clustering\n\n- No \"master\" node, all nodes are peers\n- Performance generally scales linearly with number of nodes (e.g. 2 nodes serving 100,000 transactions per second should scale to 4 nodes service 200,000 tx/s)\n\n---\n\n# Replication\n\n- The number of replicas in the cluster, i.e. copies of a particular piece of data across all nodes, is configurable on a per-keyspace (table) basis\n- If any node in a cluster goes down, one or more copies of that node’s data is available on other machines in the cluster\n- can be configured to work across one data center, many data centers, and multiple cloud availability zones\n\n---\n\n# Consistency\n\n- Consistency refers to how up-to-date and synchronized a row of data is on all of its replicas\n- Extends the concept of eventual consistency by offering tunable consistency for any given read or write operation, the client application decides how consistent the requested data should be\n\n---\n\n# Consistency (cont.)\n## Read Consistency Options (a subset)\n\n| Level | Description |\n| --- | --- |\n| ALL | Returns the record with the most recent timestamp after all replicas have responded. The read operation will fail if a replica does not respond. |\n| EACH_QUORUM | Returns the record with the most recent timestamp once a quorum of replicas in each data center of the cluster has responded. |\n| LOCAL_QUORUM | Returns the record with the most recent timestamp once a quorum of replicas in the current data center as the coordinator node has reported. |\n\n---\n\n# Consistency (cont.)\n## Read Consistency Options (a subset)\n\n| Level | Description |\n| --- | --- |\n| LOCAL_ONE | Returns a response from the closest replica, as determined by the snitch, but only if the replica is in the local data center. |\n| ONE | Returns a response from the closest replica, as determined by the snitch. By default, a read repair runs in the background to make the other replicas consistent. |\n| QUORUM | Returns the record with the most recent timestamp after a quorum of replicas has responded regardless of data center. |\n\n---\n\n# Consistency (cont.)\n## Write Consistency Options (a subset)\n\n| Level | Description |\n| --- | --- |\n| ANY | A write must be written to at least one node. If all replica nodes for the given row key are down, the write can still succeed after a _hinted handoff_ has been written. If all replica nodes are down at write time, an ANY write is not readable until the replica nodes for that row have recovered. |\n| ALL | A write must be written to the commit log and memory table on all replica nodes in the cluster for that row. |\n\n---\n# Consistency (cont.)\n## Write Consistency Options (a subset)\n\n| Level | Description |\n| --- | --- |\n| LOCAL_QUORUM | A write must be written to the commit log and memory table on a quorum of replica nodes in the same data center as the coordinator node. Avoids latency of inter-data center communication. |\n| ONE | A write must be written to the commit log and memory table of at least one replica node. |\n\n---\n\n# How is Data Stored?\n\n---\n\n## The Write Path\n\n![IMAGE](http://docs.datastax.com/en/archived/cassandra/2.0/cassandra/images/dml_write-process_12.png)\n\n---\n\n# The Write Path\n\n- Mem table - Fast immediate access\n- Commit Log - Immediate durability\n- SSTable - Long-term durability and consistency\n\n---\n\n# The Read Path\n\n![IMAGE](http://docs.datastax.com/en/archived/cassandra/2.0/cassandra/images/dml_caching-reads_12.png)\n\n---\n\n# The Read Path\n\nCassandra must combine results from the active memtable and potentially mutliple SSTables to satisfy a read.\n\n- Bloom filter - probability that a particular sstable has data before actually going to disk\n- Partition key cache - What sstable has the data?\n  - Partition Summary - Where on disk could the data be?\n  - Partition Index - Where exactly on disk is the data?\n- Compression Offsets - Where in the sstable is the data?\n- Data - There it is!\n\n# API\n\n---\n\n# Datastax\n\n---\n\n# Available Tools\n\n---\n\n# Cassandra at Socrata\n\n---\n\n# Cassandra and On-Call\n\n---\n\n# Hands-on Time\n\n---"
    }
  ]
}